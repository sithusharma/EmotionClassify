{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_path):\n",
        "    if not os.path.isfile(zip_path):\n",
        "        print(f\"The file {zip_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(extract_path):\n",
        "        os.makedirs(extract_path)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "        print(f\"Files extracted to {extract_path}\")\n",
        "\n",
        "zip_file_path = 'images.zip'\n",
        "extraction_path = 'images'\n",
        "\n",
        "unzip_file(zip_file_path, extraction_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWNhVJWG-5L5",
        "outputId": "c7bb44de-d048-4594-a237-e2f7cc5718e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the path of the folder to be deleted\n",
        "folder_path = 'images/train/disgusted'\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "    # Delete the folder\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"The folder '{folder_path}' has been deleted.\")\n",
        "else:\n",
        "    print(f\"The folder '{folder_path}' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnotVa1Hqfsk",
        "outputId": "10ed8ab5-702f-43b9-a806-ca19224ff974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder 'images/train/disgusted' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdMqqQdKq6AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras import layers, models\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from keras.layers import MaxPooling2D as MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "8Ys61JY9iq5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "\t\t\t\t\trescale=1./255,\n",
        "\t\t\t\t\trotation_range=30,\n",
        "\t\t\t\t\tshear_range=0.3,\n",
        "\t\t\t\t\tzoom_range=0.3,\n",
        "\t\t\t\t\thorizontal_flip=True,\n",
        "\t\t\t\t\tfill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "_aXN9Vkgi1Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the inbuilt keras function we can load our data\n",
        "#use the shuffle parameter to randomize and remove bias\n",
        "#validation split divides the testing and training set\n",
        "train = train_datagen.flow_from_directory(\n",
        "\t\t\t\t\t'images/train',\n",
        "\t\t\t\t\tcolor_mode='grayscale',\n",
        "\t\t\t\t\ttarget_size=(48, 48),\n",
        "\t\t\t\t\tbatch_size=32,\n",
        "\t\t\t\t\tclass_mode='categorical',\n",
        "\t\t\t\t\tshuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laRkQeMYi3wb",
        "outputId": "d193669a-00f5-4b7f-f915-2bea4758513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28273 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "validation = val_datagen.flow_from_directory(\n",
        "    'images/test',\n",
        "    color_mode='grayscale',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvc9fyGUi66Q",
        "outputId": "5f8cff99-e499-4f79-f244-45484231bf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7067 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), input_shape=(48, 48, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Conv2D(32, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Conv2D(64, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Dense(7))  # 7 classes\n",
        "# model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "ka77WoHujBL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we are telling the model to use categorical crossentropy due to our multi classification\n",
        "#we are also telling the model to use the Adam algorithm\n",
        "#finally we are telling the model to also give us accuracy rate through each epoch\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "# new_model = load_model('emotion.h5')\n",
        "# new_model.load_weights('weights.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"new_weights.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train,\n",
        "    epochs=1,    #alter this number for more or less epochs\n",
        "    validation_data=validation,\n",
        "    callbacks=[checkpoint,early]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsBW99EFjC4-",
        "outputId": "acbd83d0-e2ea-41ce-cf00-57419f319885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "884/884 [==============================] - ETA: 0s - loss: 1.6940 - accuracy: 0.2879\n",
            "Epoch 1: val_accuracy improved from -inf to 0.36550, saving model to new_weights.h5\n",
            "884/884 [==============================] - 33s 32ms/step - loss: 1.6940 - accuracy: 0.2879 - val_loss: 1.5437 - val_accuracy: 0.3655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f634923370>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('emotion.h5')"
      ],
      "metadata": {
        "id": "FCnzvbWqF3EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "model = load_model('50pEmotion.h5')\n",
        "\n",
        "# Predict the values from the test dataset\n",
        "validation.reset()\n",
        "Y_pred = model.predict(validation)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(validation.classes, y_pred)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "class_labels = list(validation.class_indices.keys())\n",
        "plot_confusion_matrix(cm, class_labels, title='Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print('Classification Report')\n",
        "print(classification_report(validation.classes, y_pred, target_names=class_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ykzjcFgSG7Sw",
        "outputId": "a6b1aa7c-549f-49cd-89eb-d48800b1fbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x78f6900c1810>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aac39e9ba35b>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'50pEmotion.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Predict the values from the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0;34mf\"No model config found in the file at {filepath}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x78f6900c1810>."
          ]
        }
      ]
    }
  ]
}